<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>JVM之OrderAcess | Corner XX daily log</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="概述OrderAcess是Java内存模型的一个重要组成部分。intel x86_64处理器在执行的时候基于性能的考虑，在store buffer(不是cache，不翻译知道意思就行)满的时候，允许处理器先处理load的指令，这样就可能导致在执行的时候处理器处理指令的时候可能和我们在程序中写的顺序是不一致的，处理器定义内存的处理器序(弱虚，处理器尽可能的优化指令的执行顺序，达到并行)和程序序(强">
<meta property="og:type" content="article">
<meta property="og:title" content="JVM之OrderAcess">
<meta property="og:url" content="http://yoursite.com/2016/09/23/jvm/OrderAccess/index.html">
<meta property="og:site_name" content="Corner XX daily log">
<meta property="og:description" content="概述OrderAcess是Java内存模型的一个重要组成部分。intel x86_64处理器在执行的时候基于性能的考虑，在store buffer(不是cache，不翻译知道意思就行)满的时候，允许处理器先处理load的指令，这样就可能导致在执行的时候处理器处理指令的时候可能和我们在程序中写的顺序是不一致的，处理器定义内存的处理器序(弱虚，处理器尽可能的优化指令的执行顺序，达到并行)和程序序(强">
<meta property="og:updated_time" content="2016-11-24T02:27:33.094Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="JVM之OrderAcess">
<meta name="twitter:description" content="概述OrderAcess是Java内存模型的一个重要组成部分。intel x86_64处理器在执行的时候基于性能的考虑，在store buffer(不是cache，不翻译知道意思就行)满的时候，允许处理器先处理load的指令，这样就可能导致在执行的时候处理器处理指令的时候可能和我们在程序中写的顺序是不一致的，处理器定义内存的处理器序(弱虚，处理器尽可能的优化指令的执行顺序，达到并行)和程序序(强">
  
    <link rel="alternative" href="/atom.xml" title="Corner XX daily log" type="application/atom+xml">
  
  
    <link rel="icon" href="//favicon.png">
  
  <script src="/style.js"></script>
</head>

<body>
  <div id="container">
    <div class="left-col">
      <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img src="/img/suolong.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Corner XX</a></h1>
		</hgroup>

		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
	        
    		
    			
    			<a class="js-smart-menu" data-idx="0" href="javascript:void(0)">所有文章</a>
    			
    			
            
    			
    			<a class="js-smart-menu" data-idx="1" href="javascript:void(0)">标签</a>
    			
    			
            
    			
    			<a class="js-smart-menu" data-idx="2" href="javascript:void(0)">关于我</a>
    			
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="#" title="github">github</a>
		        
					<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
		        
					<a class="rss" target="_blank" href="#" title="rss">rss</a>
		        
					<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/cornerxx" title="zhihu">zhihu</a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"><i class="icon-list"></i></div>
  		<h1 class="header-author js-mobile-header hide">Corner XX</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				
					<img src="/img/suolong.png" class="js-avatar">
				
			</div>
			<hgroup>
			  <h1 class="header-author">Corner XX</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="#" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="#" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/cornerxx" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap">
        <article id="post-jvm/OrderAccess" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      JVM之OrderAcess
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <a id="more"></a>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>OrderAcess是Java内存模型的一个重要组成部分。<br>intel x86_64处理器在执行的时候基于性能的考虑，在store buffer(不是cache，不翻译知道意思就行)满的时候，允许处理器先处理load的指令，这样就可能导致在执行的时候处理器处理指令的时候可能和我们在程序中写的顺序是不一致的，处理器定义内存的处理器序(弱虚，处理器尽可能的优化指令的执行顺序，达到并行)和程序序(强序，按照程序的定义执行执行)。<br>通常处理器会优化执行执行顺序，编译器也会优化执行的顺序，让执行尽可能安装处理器的顺序分布执行。这样就会导致我们在程序中声明的执行顺序和最终执行的不一致，就会导致处理器看到的内容不一致。<br>这篇就是解决这种不一致性导致了不可知的问题。<br>我们这里描述是基于intel平台的实现</p>
<h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><p>声明为volatile的变量，编译器不会做优化，可能保证变量在程序中的位置。在Java中的语义和gcc是不一样的。</p>
<h2 id="LoadLoad"><a href="#LoadLoad" class="headerlink" title="LoadLoad"></a>LoadLoad</h2><p>序列：Load1,Loadload,Load2</p>
<p>确保Load1所要读入的数据能够在被Load2和后续的load指令访问前读入。通常能执行预加载指令或/和支持乱序处理的处理器中需要显式声明Loadload屏障，因为在这些处理器中正在等待的加载指令能够绕过正在等待存储的指令。 而对于总是能保证处理顺序的处理器上，设置该屏障相当于无操作。<br>我们看看怎么实现的：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">:hotspot\src\os_cpu\linux_x86\vm\orderAccess_linux_x86.inline.hpp</div><div class="line"></div><div class="line">inline void OrderAccess::loadload()   &#123; acquire(); &#125;</div><div class="line"></div><div class="line">inline void OrderAccess::acquire() &#123;</div><div class="line">  volatile intptr_t local_dummy;</div><div class="line">#ifdef AMD64</div><div class="line">  __asm__ volatile (&quot;movq 0(%%rsp), %0&quot; : &quot;=r&quot; (local_dummy) : : &quot;memory&quot;);</div><div class="line">#else</div><div class="line">  __asm__ volatile (&quot;movl 0(%%esp),%0&quot; : &quot;=r&quot; (local_dummy) : : &quot;memory&quot;);</div><div class="line">#endif // AMD64</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>反汇编后：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">5f6f8e:       55                      push   %rbp</div><div class="line">5f6f8f:       48 89 e5                mov    %rsp,%rbp</div><div class="line">5f6f92:       48 8b 04 24             mov    (%rsp),%rax</div><div class="line">5f6f96:       48 89 45 f8             mov    %rax,-0x8(%rbp)</div><div class="line">5f6f9a:       c9                      leaveq </div><div class="line">5f6f9b:       c3                      retq</div></pre></td></tr></table></figure></p>
<p>为什么这么写呢？这段指令的作用又是什么呢？<br>在《Intel® 64 and IA-32 Architectures Software Developer’s Manual Volume 3 (3A, 3B, 3C &amp;3D):System Programming Guide》中<strong>8.2.3.2 Neither Loads Nor Stores Are Reordered with Like Operations
</strong>节，intel规定Load指令和Load指令不会重排(reorder)。这样保证Load1必须在Loadload(mov    %rax,-0x8(%rbp))指令之前执行，Loadload必须在Load2指令之前执行。这样在同一个处理器上Load1总是保证在Load2和后续的Load前执行。所以这段执行就是简单的内存Load指令。</p>
<p>在《Intel® 64 and IA-32 Architectures Software Developer’s Manual Volume 3 (3A, 3B, 3C &amp;3D):System Programming Guide》中<strong>8.2.3.5 Intra-Processor Forwarding Is Allowed
</strong>节，intel多个处理器可能看到的内存顺序就不一致了。由于store buffer的存在，不同的处理器可能看不到其他处理器对同一个内存位置的修改。</p>
<p>StoreStore  屏障</p>
<p>序列：Store1，StoreStore，Store2</p>
<p>确保Store1的数据在Store2以及后续Store指令操作相关数据之前对其它处理器可见（例如向主存刷新数据）。通常情况下，如果处理器不能保证从写缓冲或/和缓存向其它处理器和主存中按顺序刷新数据，那么它需要使用StoreStore屏障。</p>
<p>我们看看怎么实现的：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">:hotspot\src\os_cpu\linux_x86\vm\orderAccess_linux_x86.inline.hpp</div><div class="line"></div><div class="line">inline void OrderAccess::storestore() &#123; release(); &#125;</div><div class="line"></div><div class="line">inline void OrderAccess::release() &#123;</div><div class="line">  // Avoid hitting the same cache-line from</div><div class="line">  // different threads.</div><div class="line">  volatile jint local_dummy = 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>反汇编后：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">5f6f9c:       55                      push   %rbp</div><div class="line">5f6f9d:       48 89 e5                mov    %rsp,%rbp</div><div class="line">5f6fa0:       c7 45 fc 00 00 00 00    movl   $0x0,-0x4(%rbp)</div><div class="line">5f6fa7:       c9                      leaveq </div><div class="line">5f6fa8:       c3                      retq   </div><div class="line">5f6fa9:       90                      nop</div></pre></td></tr></table></figure></p>
<p>在《Intel® 64 and IA-32 Architectures Software Developer’s Manual Volume 3 (3A, 3B, 3C &amp;3D):System Programming Guide》中<strong>8.2.3.2 Neither Loads Nor Stores Are Reordered with Like Operations
</strong>节，intel规定Store指令和Store指令不会重排(reorder)。这样保证Store1必须在StoreStore(movl   $0x0,-0x4(%rbp))指令之前执行，StoreStore必须在Store2指令之前执行。这样在同一个处理器上Store1总是保证在Store2和后续的Store前执行。所以这段执行就是简单的内存Store指令。</p>
<p>LoadStore 屏障</p>
<p>序列： Load1; LoadStore; Store2</p>
<p>确保Load1的数据在Store2和后续Store指令被刷新之前读取。在等待Store指令可以越过loads指令的乱序处理器上需要使用LoadStore屏障。</p>
<p>我们看看怎么实现的：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">:hotspot\src\os_cpu\linux_x86\vm\orderAccess_linux_x86.inline.hpp</div><div class="line"></div><div class="line">inline void OrderAccess::loadstore()  &#123; acquire(); &#125;</div><div class="line"></div><div class="line">inline void OrderAccess::acquire() &#123;</div><div class="line">  volatile intptr_t local_dummy;</div><div class="line">#ifdef AMD64</div><div class="line">  __asm__ volatile (&quot;movq 0(%%rsp), %0&quot; : &quot;=r&quot; (local_dummy) : : &quot;memory&quot;);</div><div class="line">#else</div><div class="line">  __asm__ volatile (&quot;movl 0(%%esp),%0&quot; : &quot;=r&quot; (local_dummy) : : &quot;memory&quot;);</div><div class="line">#endif // AMD64</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>我们可以看出LoadLoad和LoadStore实现是一样的。为什么呢？<br>还是需要从intel文档中找答案。在《Intel® 64 and IA-32 Architectures Software Developer’s Manual Volume 3 (3A, 3B, 3C &amp;3D):System Programming Guide》中《8.2.3.3 Stores Are Not Reordered With Earlier Loads》节，我们知道如果Load执行在前面，那么后面的store的执行不会重排(reorder)，这样就保证Load1的数据在Store2和后续Store指令被刷新之前读取。</p>
<p>StoreLoad Barriers</p>
<p>序列: Store1; StoreLoad; Load2</p>
<p>确保Store1的数据在被Load2和后续的Load指令读取之前对其他处理器可见。StoreLoad屏障可以防止一个后续的load指令 不正确的使用了Store1的数据，而不是另一个处理器在相同内存位置写入一个新数据。正因为如此，所以在下面所讨论的处理器为了在屏障前读取同样内存位置存过的数据，必须使用一个StoreLoad屏障将存储指令和后续的加载指令分开。Storeload屏障在几乎所有的现代多处理器中都需要使用，但通常它的开销也是最昂贵的。它们昂贵的部分原因是它们必须关闭通常的略过缓存直接从写缓冲区读取数据的机制。这可能通过让一个缓冲区进行充分刷新（flush）,以及其他延迟的方式来实现。<br>我们看看怎么实现的：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">:hotspot\src\os_cpu\linux_x86\vm\orderAccess_linux_x86.inline.hpp</div><div class="line"></div><div class="line">inline void OrderAccess::storeload()  &#123; fence(); &#125;</div><div class="line"></div><div class="line">inline void OrderAccess::fence() &#123;</div><div class="line">  if (os::is_MP()) &#123;</div><div class="line">    // always use locked addl since mfence is sometimes expensive</div><div class="line">#ifdef AMD64</div><div class="line">    __asm__ volatile (&quot;lock; addl $0,0(%%rsp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);</div><div class="line">#else</div><div class="line">    __asm__ volatile (&quot;lock; addl $0,0(%%esp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);</div><div class="line">#endif</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从代码中我们可以知道这是个重量级的操作，使用lock前缀，而且是一个空操作(将0加到栈顶)，在《Intel® 64 and IA-32 Architectures Software Developer’s Manual Volume 3 (3A, 3B, 3C &amp;3D):System Programming Guide》<strong>8.2.3.9 Loads and Stores Are Not Reordered with Locked Instructions</strong>节规定使用lock前缀的执行不允许排序，不管是store还是load。所以我们知道这个屏障其实也是最重量的实现，也是对性能影响最大的操作。</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="Memory-Reording-Caught-in-Act"><a href="#Memory-Reording-Caught-in-Act" class="headerlink" title="Memory Reording Caught in Act"></a>Memory Reording Caught in Act</h3><p>前言：<br>首先是翻译的几篇有关memory reordering的文章，作者是一个老外，虽然文章是几年前的，但是很值得一读。<br>最近不知道写些什么东西，拿这个先凑几篇<br>其次有关什么memory ordering，memory reordering，memory model这些名词，可能很多时候直接e文，没有翻译，个人习惯。</p>
<h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a><a href="http://preshing.com/20120515/memory-reordering-caught-in-the-act/" target="_blank" rel="external">原文</a></h2><p>当使用C或者C++编写lock-free的代码时，你必须特别小心的保证正确的内存顺序。否则的话，会遇到不少“惊喜”。</p>
<p>Intel在它们的x86/64体系结构规范的第三卷8.2.3节列举了几种这样的case。拿最简单的那个例子来说。假设在内存中有两个整数变量x和y，都初始化为0，两个并行运行的processor执行下面的机器码：<br>乱序的例子<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">                | Processor 1  | Processor 1 |</div><div class="line"> store to X ---&gt;|mov [X], 1    | mov [Y],1   | &lt;---store to Y</div><div class="line">load form Y ---&gt;|mov r1 , [Y]  | mov r2 ,[X] | &lt;---load from X</div></pre></td></tr></table></figure></p>
<p>别被其中的汇编语言吓到，这其实是描述CPU执行顺序的最佳方式。每个processor将1保存到其中一个整形变量，然后将另外一个变量读取到一个register（这里r1和r2是表示x86 register的符号，比如eax）。</p>
<p>现在，无论哪个processor先把1写到内存，很自然我们期望另一个processor会把这个值读出来，也就是说，代码执行完后，我们应该得到的结果是：r1=1或者r2=1，或者r1和r2都是1。但是，根据Intel的规范，结果并不总是这样，规范说本例还有另外一种合法的结果：r1和r2都是0——一个违反直觉的结果。</p>
<p>因为像其它的处理器家族一样，Intel x86/64处理器在特定的规则下允许将内存指令重排序，只要不会改变单线程程序的执行（as long it never changes the execution of a single-threaded program）。<br>特别的，每一个processor都允许将一个store的影响推迟到任何读取其它内存的load之后（each processor is allowed to delay the effect of a store past any load from a different location）。结果就是，实际上可能根据如下的指令顺序来执行的：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">     | Processor 1  | Processor 2  |</div><div class="line">---&gt; | mov r1 ,[Y]  |              |</div><div class="line">|    |              | mov r2 ,[X]  | &lt;---</div><div class="line">---&gt; | mov [X],1    |                    |</div><div class="line">                    | mov [Y],1    | &lt;---</div></pre></td></tr></table></figure></p>
<p>–&gt;Spark注：这里作者只是介绍了StoreLoad内存序，实际上基于store和load有4种内存序，这是CPU内存模型的主要部分，在后面的文章中会专门介绍。还有就是MOV r1, [y]实际上有两步：读y写r1；<br>以P1为例上面的操作实际上是三步：store x; load y; store r1;</p>
<h4 id="Let’s-Make-It-Happen"><a href="#Let’s-Make-It-Happen" class="headerlink" title="Let’s Make It Happen"></a>Let’s Make It Happen</h4><p>有人告诉你可能会出现这种结果也是不错的，但是还远不如亲眼看到这种结果。所以我写了一个小程序来说明这种乱序确实会发生，源代码在这里。<br>示例代码包括Win32和POSIX两个版本，它创建两个工作线程，无限重复上面的事务，然后主线程同步并检查它们的结果。</p>
<p>这是第一个工作线程的代码。X, Y, r1和r2都是全局变量，POSIX信号量用于协调每次循环的开始和结束。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">sem_t beginSema1;</div><div class="line">sem_t beginSema2;</div><div class="line">sem_t endSema;</div><div class="line"></div><div class="line">int X, Y;</div><div class="line">int r1, r2;</div><div class="line"></div><div class="line">void *thread1Func(void *param) &#123;</div><div class="line">    MersenneTwister random(1);</div><div class="line">    for (;;) &#123;</div><div class="line">        sem_wait(&amp;beginSema1);  // Wait for signal</div><div class="line">        while (random.integer() % 8 != 0) &#123;&#125;  // Random delay</div><div class="line"></div><div class="line">        // ----- THE TRANSACTION! -----</div><div class="line">        X = 1;</div><div class="line">        asm volatile(&quot;&quot; ::: &quot;memory&quot;);  // Prevent compiler</div><div class="line">        r1 = Y;</div><div class="line"></div><div class="line">        sem_post(&amp;endSema);  // Notify transaction complete</div><div class="line">    &#125;</div><div class="line">    return NULL;  // Never returns</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>这段代码在每次事务之前加了一个随机的短暂延迟，这是为了让线程的运行时间交错。记住，一共有两个工作线程，我们要试着让它们的指令执行产生重叠。随机延迟是使用的是前面几篇文章中中实现的MersennelTwister，比如measuring lock contention。<br>注spark：这里不需要关注这个MersennelTwister，其实直接使用rand()函数也是一样的，在 main中srand(time(0))；测试结果不变，而且碰撞的概率更高。</p>
<p>也不要被代码中的asm volatile吓到，这只是告诉GCC编译器在生成机器码时不要重排store和load操作的指令顺序，防止它在优化时搞什么我们不想要的花样。我们可以检查汇编代码来验证这一点，比如下面的代码片段。如同所期望的那样，store和load指令是期望的顺序。后面的指令将保存结果的register eax写回到了全局变量r1。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ gcc -O2 -c -S -masm=intel ordering.cpp</div><div class="line">$ cat ordering.s</div><div class="line">    ...</div><div class="line">    mov    DWORD PTR _X, 1</div><div class="line">    mov    eax, DWORD PTR _Y</div><div class="line">    mov    DWORD PTR _r1, eax</div><div class="line">    ...</div></pre></td></tr></table></figure></p>
<p>主线程代码如下，就是一个管理工作。它在初始化之后无限循环，每次循环之前将X和Y重置为0。<br>特别注意程序是如何让写共享内存发生在sem_post之前的，以及让所有读共享内存发生在sem_wait之后的。工作线程和主线程之间的通信也采用了同样的机制。<br>在所有平台上，Semaphores都给我们提供了acquire-release语义，这个后面会仔细分析。这就意味着，我们保证X=0和Y=0的初始化结果会完整的传播给工作线程，r1和r2的结果都会完整的传播回来。换句话说，semaphores防止我们程序框架的memory reordering，让我们专注于测试StoreLoad reordering的情况。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">int main() &#123;</div><div class="line">    // Initialize the semaphores</div><div class="line">    sem_init(&amp;beginSema1, 0, 0);</div><div class="line">    sem_init(&amp;beginSema2, 0, 0);</div><div class="line">    sem_init(&amp;endSema, 0, 0);</div><div class="line"></div><div class="line">    // Spawn the threads</div><div class="line">    pthread_t thread1, thread2;</div><div class="line">    pthread_create(&amp;thread1, NULL, thread1Func, NULL);</div><div class="line">    pthread_create(&amp;thread2, NULL, thread2Func, NULL);</div><div class="line">    // Repeat the experiment ad infinitum</div><div class="line">    int detected = 0;</div><div class="line">    for (int iterations = 1; ; iterations++) &#123;</div><div class="line">        // Reset X and Y</div><div class="line">        X = 0;</div><div class="line">        Y = 0;</div><div class="line">        // Signal both threads</div><div class="line">        sem_post(&amp;beginSema1);</div><div class="line">        sem_post(&amp;beginSema2);</div><div class="line">        // Wait for both threads</div><div class="line">        sem_wait(&amp;endSema);</div><div class="line">        sem_wait(&amp;endSema);</div><div class="line">        // Check if there was a simultaneous reorder</div><div class="line">        if (r1 == 0 &amp;&amp; r2 == 0) &#123;</div><div class="line">            detected++;</div><div class="line">            printf(&quot;%d reorders detected after %d iterations\n&quot;, </div><div class="line">                                           detected, iterations);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    return 0;  // Never returns</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>运行结果显示，发生了很多次的重排序，也就是结果r1和r2都是0：<br>注spark：下面都是我自己的测试结果。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1 reorders detected after 1 iterations</div><div class="line">2 reorders detected after 2 iterations</div><div class="line">3 reorders detected after 3 iterations</div><div class="line">... ...</div><div class="line">31 reorders detected after 799 iterations</div><div class="line">32 reorders detected after 1058 iterations</div></pre></td></tr></table></figure></p>
<p>而且可以看出概率相当的高，简直是必现，我这里是Mac系统，Intel Core i5处理器；<br>换到Linux继续测试，Intel x86_64处理器，概率相对低一些：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1 reorders detected after 4760 iterations</div><div class="line">2 reorders detected after 6671 iterations</div><div class="line">3 reorders detected after 8859 iterations</div><div class="line">4 reorders detected after 12980 iterations</div></pre></td></tr></table></figure></p>
<p>好了，我们当然期望能消除这种乱序。至少有两种方法可以做到，一个是设置线程的CPU亲缘性，这样两个线程都运行在同一个CPU core上，在Linux：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">cpu_set_t cpus;</div><div class="line">CPU_ZERO(&amp;cpus);</div><div class="line">CPU_SET(0, &amp;cpus);</div><div class="line">pthread_setaffinity_np(thread1, sizeof(cpu_set_t), &amp;cpus);</div><div class="line">pthread_setaffinity_np(thread2, sizeof(cpu_set_t), &amp;cpus);</div></pre></td></tr></table></figure></p>
<p>因为单个processor看到自己的操作肯定不会是乱序的，即使在线程被任意次的抢占和重新调度但。很显然，这并不是好方法。<br>—&gt;spark注：<br>可以再引申一下：<br>在单processor下，下面的执行顺序都是合法的：<br>1 线程1：x = 1; r2 = y; -&gt; 线程2：r1 = x; y = 1;<br>仅仅线程2中顺序重排，不违反原则，对x的reads没有和线程1中的写x=1重排序；<br>2 线程1：r2 = y; x = 1; -&gt; 线程2：y = 1; r1 = x;<br>仅仅线程1中顺序重排，不违反原则，对y的reads没有和线程2中的写y=1重排序；<br>单processor上，对同一地址的loads不能提前到它前面的stores而先执行，这应该是所有CPU体系结构的共同原则，否则就是错误！所以将这两个线程绑定在同一个processor上不会再出现r1和r2都是0的情况。<br>&lt;—over<br>一个相关的note，在PlayStation3上，没有检测到内存乱序。这显示（但并不能确定）两个PPU内的硬件线程可能像单一的processor在运行，有很细粒度的硬件调度。</p>
<h4 id="Preventing-It-With-a-StoreLoad-Barrier"><a href="#Preventing-It-With-a-StoreLoad-Barrier" class="headerlink" title="Preventing It With a StoreLoad Barrier"></a>Preventing It With a StoreLoad Barrier</h4><p>另外一个方法就是在两个操作之间引入CPU barrier，这里我们要防止store和它后面的load指令重排。用通常的barrier说法就是，我们需要一个StoreLoad barrier。</p>
<p>虽然x86/64处理器没有专门的用作StoreLoad barrier的指令，但是有好几个指令包含了StoreLoad的功能，并且还可以做得更多。mfence指令是一个全内存barrier，它防止任何情况下的memory reordering，在GCC下，代码可以这样写：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">for (;;)   &#123;                               // Loop indefinitely</div><div class="line">    sem_wait(&amp;beginSema1);                // Wait for signal from main thread</div><div class="line">    while (random.integer() % 8 != 0) &#123;&#125;  // Add a short, random delay</div><div class="line"></div><div class="line">    // ----- THE TRANSACTION! -----</div><div class="line">    X = 1;</div><div class="line">    asm volatile(&quot;mfence&quot; ::: &quot;memory&quot;);  // Prevent memory reordering</div><div class="line">    r1 = Y;</div><div class="line"></div><div class="line">    sem_post(&amp;endSema);                   // Notify transaction complete</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>再次查看汇编代码验证：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">...</div><div class="line">mov    DWORD PTR _X, 1</div><div class="line">mfence</div><div class="line">mov    eax, DWORD PTR _Y</div><div class="line">mov    DWORD PTR _r1, eax</div><div class="line">...</div></pre></td></tr></table></figure></p>
<h4 id="Similar-Instructions-and-Different-Platforms"><a href="#Similar-Instructions-and-Different-Platforms" class="headerlink" title="Similar Instructions and Different Platforms"></a>Similar Instructions and Different Platforms</h4><p>有趣的是，mfence不是x86/64上唯一可以用作full memory barrier的指令，在这些处理器上，任何锁指令，比如xchg，也可以用作full memory barrier——当你不使用SSE指令或者写组合内存时。实际上至少在VS2008之前，当你使用MemoryBarrier时，Microsoft C++生成的都是xchg指令~~~</p>
<p>而mfence指令是x86/64特有的，如果你希望跨平台，就需要自己自己wrap一个。Linux内核wrap了一个smp_mb的宏，类似的还有smb_rmb和smp_wmb。比如在PowerPC上，smp_mb就是sync。<br>所有不同的CPU家族，都有自己的强制memory ordering的指令，每一个跨平台的项目都需要实现自己的跨平台代码库，这显然不是一个轻松的事情。这也是为什么C++11引入了atomic库标准，这会简化编写可移植lock-free代码的工作量。</p>
<h4 id="评论摘选"><a href="#评论摘选" class="headerlink" title="评论摘选"></a>评论摘选</h4><p>文章有些评论很不错，这条是来自于Bruce Dawson：<br>非常不错——写测试代码来验证是不错的注意。<br>我想对本文提出一点修正和解释。<br>修正之处就是：reads/writes的重排序和指令重排序是正交的（没有必然联系）。Xbox360 CPU不会做指令重排序，但是底层的reads/writes却会重排序。实际上相比Xbox360这种有序的CPU，Intel/AMD这些out-of-oder的CPUs上对read/write的重排序还少很多。</p>
<p>这种情况下，在光速有限的宇宙中，任何多核系统中reordering都是不可避免的。如果两个processor同时write 1，期望它们可以在下一个指令就可以看到彼此的write是不切实际的。实际上，这个write传播到其它core可能需要花费数十个CPU周期。任何防止这种重排序的系统，它的运行速度不可能超过100MHz，甚至更慢。因为一个它必须不断的等待其它core的signal（等待其它core对write的响应）。<br>—-&gt;spark注：多说一点，现代CPU为了提升执行速度，通常都会采用多级cache，每个core都会自己的一级cache。由于这些cache的存在，读写的reordering是难以避免的，相比指令乱序，它是导致memory reordering的更主要的原因。<br>正如Bruce Dawson所说的：<br>如果要保持各个core的cache之间严格一致，那么每次更新都要等待其它core的响应。这样的话，CPU的速度就不然被限制了。</p>
<h3 id="MEMORY-ORDERING"><a href="#MEMORY-ORDERING" class="headerlink" title="MEMORY ORDERING"></a>MEMORY ORDERING</h3><p>前言：这篇文章是翻译自的Intel x86/64的规范文档，其中第8.2节中有关Memory Ordering的几段。整个文档是一本巨书，这里可以download：<a href="http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-system-programming-manual-325384.pdf" target="_blank" rel="external">http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-system-programming-manual-325384.pdf</a><br>因为我们有必要了解一下CPU对memory ordering的规范说明，这里我们看看Intel的。</p>
<hr>
<p>术语memory ordering指的是，processor以何种顺序通过系统总线发起到系统内存的读（loads）和写（stores）操作。基于体系结构的实现，Intel64和IA-32支持好几种memory-ordering模型。比如Intel386处理器强制执行程序顺序（通常被称为strong ordering（强排序）），在任何情况下，对系统总线发起的读和写都是根据他们在指令流中的顺序进行的。<br>为了优化指令执行的性能，IA-32体系结构允许违背strong ordering模型，在P4，Xeon和P6 processor家族中，这被称为processor ordering。这些processor-ordering变形（这里成为memory ordering模型）允许提升性能的而一些操作，比如允许读提升到缓存写的前面。这些变形的目的都是为了在维持内存conherency的基础上提升执行的速度，甚至在多核系统中。</p>
<h3 id="Memory-Ordering-in-the-Pentium-and-Intel486-Processors"><a href="#Memory-Ordering-in-the-Pentium-and-Intel486-Processors" class="headerlink" title="Memory Ordering in the Pentium and Intel486 Processors"></a>Memory Ordering in the Pentium and Intel486 Processors</h3><p>Pentium和Intel486 processor遵循processor-ordered内存模型，然而在大多数情况下，它们都是按照strong-ordered processor运行的。在系统总线上的读和写通常都是程序序——除了如下的情况会展现出processor ordering。当所有的buffered write cache命中时，Read misses允许被提升到对系统总线的buffered writes之前，因此buffered write不会同时指向被read miss访问的同一块地址上（因为buffered write cache命中）。<br>在I/O操作的情形，读和写都是根据程序序。<br>期望在processor-ordered processor上正确执行的软件不应该依赖Pentium和Intel486的相对strong ordering。相反，应该保证对共享变量的访问如果要控制processor之间的并发执行，要显式的使用lock和序列化操作来保证程序序。</p>
<h3 id="Memory-Ordering-in-P6-and-More-Recent-Processor-Families"><a href="#Memory-Ordering-in-P6-and-More-Recent-Processor-Families" class="headerlink" title="Memory Ordering in P6 and More Recent Processor Families"></a>Memory Ordering in P6 and More Recent Processor Families</h3><p>Intel Core 2Duo，Atom，Core Duo，Pentium4和P6家族使用的processor-ordered memory-ordering模型，又可以被进一步定义为：write ordered with store-buffer forwarding。这种模型的特性如下面的描述：<br>在single-processor系统中对于被定义为write-back cacheable的内存区域，memory-ordering模型有如下的原则（注意对于single和multiple processor的memory-ordering原则都是从在processor上执行的软件的角度来说的，这里的属于processor指的是logical processor。比如，一个支持multiple core或者Intel Hyper-Threading计数的物理processor也被当做multi-processor系统看待）：</p>
<p>1 读和读不会重排序；Reads are not reordered with other reads<br>2 写和older读不会重排序；Writes are not reordered with older reads;<br>3 写和写不会重排序；Writes are not reordered with other writes，除了如下情况：<br>— 使用nonn-temporal move指令（MOVNT1, MOVENTQ，MOVNTDQ等）的streaming<br>stores（writes）<br>— string操作（见8.2.4.1）<br>4 Reads可能会和对不同地址的older writes重排序，但是同一地址不会（prefetch？）<br>5 Reads不能越过前面的LFENCE和MFENCE指令；<br>6 还有其它规则，不一一列举了，直接看文档；<br>在multiple-processor系统上应用了如下的规则：</p>
<p>1 单processor使用和single-processor系统相同的规则<br>2 一个processor的writes会按照相同的顺序对所有的processor可见<br>3 一个processor的writes不要求与其它processor的writes有序<br>Writes from a single processor are NOT ordered with respect to<br>the writes from other processors<br>4 Memory ordering遵从因果关系（memory ordering遵守传递可见性）<br>Memory ordering byes causality (memory ordering respects transitive visibility)<br>5 Lock指令是全序的，Locked instructions have a total order</p>
<h3 id="Examples-Illustrating-the-Memory-Ordering-Principles"><a href="#Examples-Illustrating-the-Memory-Ordering-Principles" class="headerlink" title="Examples Illustrating the Memory-Ordering Principles"></a>Examples Illustrating the Memory-Ordering Principles</h3><p>本节提供几个例子来说明8.2.2节中介绍的memory-ordering原则下的行为；可以帮助软件编写者明白memory ordering可能影响指令不同顺序时的结果。<br>这些例子仅限于访问被定义为write-back cacheable（WB）的内存区域（8.2.3.1节描述了其它的一些限制）。读者应该明白它们只是描述了对软件可见的行为。一个logic processor也可能重排两个access，即使一个例子表示他们可能没有重排。<br>这个例子只是说明软件不能检测出这样的一个重排发生了。类似的，一个logic processor可能会多次执行一个内存access操作，只要对软件来说这个行为和只执行一次内存access的结果是一致的。</p>
<h4 id="Assumptions-Terminology-and-Notion"><a href="#Assumptions-Terminology-and-Notion" class="headerlink" title="Assumptions, Terminology, and Notion"></a>Assumptions, Terminology, and Notion</h4><p>前面说过的，本节中的例子仅限于访问被定义为write-back cacheable（WB）的内存区域。它们只应用在通常的loads stores，已经locked read-modify-write指令。并不应用于如下的几种情况：string指令的out-of-order stores（8.2.4节）；等等，后面集中不翻译了。</p>
<p>本节例子的基础原则适用于单个的memory accesses和locked read-modify-write指令。Intel-64 memory-ordering模型保证：下面的每一种memory-access指令，其内存操作看来就像执行一个单个的内存访问。</p>
<p>1 读写单个byte；<br>2 读写单个word(2 bytes)，地址对齐在2 byte；<br>3 读写单个double word（4 bytes），字节对齐在4 byte；<br>4 读写单个quadword（8 bytes），字节对齐在8byte；<br>任何locked指令（XCHG或者其它任何待LOCK前缀的read-modify-write指令）看起来就像执行不可见的不可中断的顺序：load(s) followed by store(s)，并且忽略对齐。<br>其它指令可能会实现成多个内存访问。从memory-ordering的角度看，并且没有相对顺序的保证。</p>
<p>8.2.3.2到8.2.3.7给了使用MOV指令的例子，这些例子中的原则同样用于通用的load和store，以及其它从内存load或者向内存的store的指令。</p>
<p>本节中的术语“processor”代表的是logic processor，例子是基于Intel-64汇编语言语法，并且使用如下的符号约定：</p>
<p>1 使用r开头的变量，比如r1和r2，代表了寄存器；<br>2 内存地址用x,y,z表示；<br>3 Store操作写作 mov [_x], val，表示将val存储到地址x中；<br>4 Load操作写作mov r, [_x]，表示读取地址x中的内容并保存到寄存器r；<br>再说一遍，例子仅仅代表从软件的角度看到的行为，当后面的小节说“这两个stores被重排序了”，指的是“从软件的角度看，这两个stores重排序了”。</p>
<h4 id="Neither-Loads-Nor-Stores-Are-Reordered-with-Like-Operations"><a href="#Neither-Loads-Nor-Stores-Are-Reordered-with-Like-Operations" class="headerlink" title="Neither Loads Nor Stores Are Reordered with Like Operations"></a>Neither Loads Nor Stores Are Reordered with Like Operations</h4><p>在Intel-64 memory-ordering模型中，loads和loads之间，以及stores和stores之间是绝对不允许重排序的。也就是说，它保证，loads和程序序一致，stores和程序序一致；比如如下的例子：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1 | Processor 0            |  Processor 1  |</div><div class="line">2 | mov [_x], 1            |  mov r1, [_y] |</div><div class="line">3 | mov [_y], 1            |  mov r2, [_x] |</div></pre></td></tr></table></figure></p>
<p>初始值x = y = 0，执行结果r1=1，r2=0是不允许的。<br>这种不允许的结果只有在如下的两种情况下才会出现：<br>1 processor0的两个stores重新排序了；（processor1的两个loads在它们中间执行）<br>2 或者processor1的两个loads重新排序了；（processor0的两个stores在它们中间执行）</p>
<p>如果r1=1，那么对y的store操作早于对y的load操作。（继续）因为Intel-64 memory-ordering模型不允许store之间重排序，所以对x的store早于对y的load。因为也不允许loads之间重新排序，所以对x的store也早于对x的load，因此r2=1。</p>
<h4 id="Stores-Are-Not-Reordered-With-Earlier-Loads"><a href="#Stores-Are-Not-Reordered-With-Earlier-Loads" class="headerlink" title="Stores Are Not Reordered With Earlier Loads"></a>Stores Are Not Reordered With Earlier Loads</h4><p>Intel-64 memory-ordering保证，对于同一个processor，store操作不能在在它前面的load之前执行；用如下的例子说明：<br>例子：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1 |  Processor 0              |  Processor 1</div><div class="line">2 |  mov r1, [_x]             |  mov r2, [_y]</div><div class="line">3 |  mov [_y], 1              |  mov [_x], 1</div></pre></td></tr></table></figure></p>
<p>初始值x = y = 0，执行结果r1=1，r2=1是不允许的。</p>
<p>假设r1 = 1；</p>
<blockquote>
<p>因为r1=1，processor1的store to x早于processor0的load from x；<br>因为Intel-64 memory-ordering模型阻止在同一个processor上store与它前面的loads重新排序， 所以processor1的load from y早于它的store to x；<br>同样的，processor0的load from x早于它的store to y；<br>所以，processor1的load from y早于processor0的store to y，暗示r2=0；</p>
<h4 id="Loads-May-be-Reordered-with-Earlier-Stores-to-Different-Locations"><a href="#Loads-May-be-Reordered-with-Earlier-Stores-to-Different-Locations" class="headerlink" title="Loads May be Reordered with Earlier Stores to Different Locations"></a>Loads May be Reordered with Earlier Stores to Different Locations</h4></blockquote>
<p>这就是前面文章中的那个例子，Intel-64 memory-ordering模型下，load可以和前面的store重新排序，但是只能是对不同的地址。<br>例子1：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1 |Processor 0              |  Processor 1</div><div class="line">2 |mov [_x], 1              |  mov [_y], 1</div><div class="line">3 |mov r1, [_y]             |  mov r2, [_x]</div></pre></td></tr></table></figure></p>
<p>初始值x = y = 0，执行结果r1=0，r2=0是允许的。<br>在每一个processor上，load和store都是操作不同的地址，因此可以重排序。操作的任意交叉都是允许的，当两个loads早于两个stores执行时，就会出现r1=0和r2=0的结果。</p>
<p>对于同一个地址，则不允许，如下面的例子2：<br>Processor 0<br>mov [_x], 1<br>mov r1, [_x]<br>初始值x=0，那么r1=0是不允许的。<br>很显然如果mov r1, [_x]先执行，即使对于单线程程序，整个结果也是错误的。也就是前面的例子1在设置cpu affinity后，不会再出现r1=0和r2=0的结果。<br>虽然是两个线程，但是对于processor而言，对同一内存地址，load不能前面的store重排序。（对于processor其实是没有线程的概念的，在processor的视角上，只是对内存的store和load指令序列）</p>
<h4 id="Intra-Processor-Forwarding-is-Allowed"><a href="#Intra-Processor-Forwarding-is-Allowed" class="headerlink" title="Intra-Processor Forwarding is Allowed"></a>Intra-Processor Forwarding is Allowed</h4><p>Intel-64 memory-ordering模型允许两个processor的并发store时，这两个processor看到的顺序可能互不不同。特别的，每一个processor可能认知它自己的store发生在另一个processor之前。用如下的例子说明：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1 |Processor 0            |  Processor 1</div><div class="line">2 |mov [_x], 1            |  mov [_y], 1</div><div class="line">3 |mov r1, [_x]           |  mov r3, [_y]</div><div class="line">4 |mov r2, [_y]           |  mov r4, [_x]</div></pre></td></tr></table></figure></p>
<p>初始值x = y = 0；结果r2 = r4 = 0是允许的。<br>Memory-ordering对于两个processor执行的两个stores的顺序没有任何的限制。于是processor0看到自己的store早于processor1的，而processor1则看到自己的store早于processor0的（每一个processor都是自我一致性的），这就允许r2=r4=0；</p>
<p>在实际中，本例的这种重排现象会导致store-buffer forwarding这一结果。当store被临时的放在一个processor的store buffer中，这可以满足processor自己的load，但是却不能被其它的processor看到，因而不能load最新的结果。</p>
<h4 id="Stores-Are-Transitively-Visible"><a href="#Stores-Are-Transitively-Visible" class="headerlink" title="Stores Are Transitively Visible"></a>Stores Are Transitively Visible</h4><p>Intel64保证store的可见性是传递的，stores that are causally related appear to all<br>processors to occur in an order consistent with the causality relation。下面的例子：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1 |Process 0             | Processor 1               | Process 2</div><div class="line">2 |mov [_x], 1           | mov r1, [_x]              |</div><div class="line">3 |                      | mov [_y], 1               | mov r2, [_y]</div><div class="line">4 |                      |                           | mov r3, [_x]</div></pre></td></tr></table></figure></p>
<p>初始值x = y = 0; r1=1, r2 = 1, r3 = 0是不允许的；<br>假设r1 = r2 = 1；</p>
<blockquote>
<p>因为r1 = 1，processor0的store早于processor1的load；<br>因为Intel64不允许store和前面的load重排序（见2.4.3），processor1的load早于它的store；因此processor0的store早于processor1的store；<br>因为processor0的store早于process1的store，memory-ordering模型保证了从所有processor的角度看，processor0的store早于processor1的store；<br>因为r2 = 1，processor1的store早于processor2的load；<br>因为Intel64阻止了load之间的重排序，processor2的load是根据次序发生的；<br>上面的条目暗示了processor0对x的store发生于processor2从x的load，因此r3 = 1；</p>
<h4 id="Stores-Are-Seen-in-a-Consistent-Order-by-Other-Processors"><a href="#Stores-Are-Seen-in-a-Consistent-Order-by-Other-Processors" class="headerlink" title="Stores Are Seen in a Consistent Order by Other Processors"></a>Stores Are Seen in a Consistent Order by Other Processors</h4></blockquote>
<p>就像2.4.5节提到的，对于两个processor的stores，memory-ordering允许它们看到不同的顺序。然而对于它们之外的其它的processor而言，这两个store的执行顺序必须看起来是一致的。用下面的例子说明：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1 |Processor 0   | Processor 1    | Processor 2    | Processor 3</div><div class="line">2 |mov [_x], 1   | mov [_y], 1    | mov r1, [_x]   | mov r3, [_y]</div><div class="line">3 |                               | mov r2, [_y]   | mov r4, [_x]</div></pre></td></tr></table></figure></p>
<p>初始值x = y = 0，r1 = 1, r2 = 0, r3 = 1, r4 = 0是不允许的。<br>基于2.4.3的原则：</p>
<blockquote>
<p>processor2的两个load不能重排序；<br>processor3的两个load不能重排序；<br>如果r1 = 1， 并且r2 = 0，那么在processor2看来，processor0的store早于<br>processor1的store；<br>同样的，r3 = 1并且r4 = 0暗示了processor1的store早于processor0的store<br>（注：这里应该是从processor3的角度）<br>因为本条规则保证了：对于其它的processor，它们看到的任何两条store的执行顺序都需要是一致的；那么这个结果无疑违反了这个原则。<br>好了，后面还有其它的几个例子，不列举了，到这里应该足够了。</p>
</blockquote>
<h3 id="Memory-Ordering-at-Compile-Time"><a href="#Memory-Ordering-at-Compile-Time" class="headerlink" title="Memory Ordering at Compile Time"></a>Memory Ordering at Compile Time</h3><p>JUN 25, 2012 <a href="http://preshing.com/20120625/memory-ordering-at-compile-time/" target="_blank" rel="external">原文</a></p>
<p>从你写C/C++源代码到它在CPU里执行，这段代码的内存交互可能会根据特定的规则被重新排序了。编译器（编译期）和processor（运行期）都有可能导致内存序的改变，都是为了能够让你的代码运行的更快。<br>对于memory reordering，被编译器开发者和CPU制造商广泛遵循的主要原则就是：<br>绝对不能修改单线程程序的行为；<br>Thou shalt not modify the behavior of a single-threaded program.</p>
<p>这条规则的结果就是，对于单线程代码，程序员完全无需关注memory reordering。通常多线程程序也不需要关注，因为从设计上，mutex， semaphore和event都会在它们的调用点防止memory reordering。仅仅在编写lock-free代码时memory reordering才可能会出来捣乱——被多线程共享的内存没有任何的互斥锁，memory reordering的影响很容易观察到，可见前一章的例子。</p>
<p>需要提醒你的是，在编写多核平台上的lock-free代码时还是有方法可以回避memory reordering的困难。就像在introduction to lock-free programming中提到的，你可以利用sequential consistent类型，比如Java中的volatile和C++11的atomic——可能只是很小的性能代价。这里不再深入说了。本篇文章，我将集中关注编译器memory reordering对常规的non-consequential-consistent类型的影响。</p>
<h4 id="Compiler-Instruction-Reordering"><a href="#Compiler-Instruction-Reordering" class="headerlink" title="Compiler Instruction Reordering"></a>Compiler Instruction Reordering</h4><p>如你所知，编译器的职责就是将源代码转换为CPU可以执行的机器码，在转换过程中，编译器有许多自由空间可以操作。<br>compiler-reordering<br>其中一种自由就是指令重排序——再一次，只有单线程程序的行为不会修改。这种指令重排序只是在开启了编译优化时才生效。考虑下面的函数：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">int A, B;</div><div class="line">void foo() &#123;</div><div class="line">    A = B + 1;</div><div class="line">    B = 0;</div><div class="line">&#125;</div><div class="line">`</div></pre></td></tr></table></figure></p>
<p>如果我们在关闭编译优化的情况下使用GCC4.6.1编译这个函数，它会生成如下的机器码，对全局变量B的store刚好在对A的store之后，就像在源代码中那样。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ gcc -S -masm=intel foo.c</div><div class="line">$ cat foo.s</div><div class="line">        ...</div><div class="line">        mov     eax, DWORD PTR _B  (redo this at home...)</div><div class="line">        add     eax, 1</div><div class="line">        mov     DWORD PTR _A, eax</div><div class="line">        mov     DWORD PTR _B, 0</div><div class="line">        ...</div></pre></td></tr></table></figure></p>
<p>注意上面的mov DWORD PTR B, 0的位置，这一语句是对B的赋值。然后开启-O2优化再编译一次，对比看看：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ gcc -O2 -S -masm=intel foo.c</div><div class="line">$ cat foo.s</div><div class="line">        ...</div><div class="line">        mov     eax, DWORD PTR B</div><div class="line">        mov     DWORD PTR B, 0</div><div class="line">        add     eax, 1</div><div class="line">        mov     DWORD PTR A, eax</div><div class="line">        ...</div></pre></td></tr></table></figure></p>
<p>这一次，编译器自由发挥了，将对B的store重新排序到了对A store的前面。有何不可呢？这并没有破坏memory reordering的规则：一个单线程执行的程序永远不知道这种差异。</p>
<p>在另一方面，这样的编译器reordering会使lock-free代码产生问题。下面就是一个被广泛引用的例子，一个共享flag用来表示另外的一些共享数据是否ready：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">int Value;</div><div class="line">int IsPublished = 0;</div><div class="line"></div><div class="line">void sendValue(int x) &#123;</div><div class="line">    Value = x;</div><div class="line">    IsPublished = 1;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>想象一下，如果编译器将对IsPublished的store操作重排到对value的store操作之前，会发生什么。即使在单核系统上，我们也会遇到一个问题：一个线程可能正好在执行这两个store操作之间被操作系统抢占，其它线程将会相信value已经更新了，而其实并没有。</p>
<p>当然，编译器可能不会重排这些操作，生成的机器码是lock-free的操作，并且可以在任何具有强内存模型的多核CPU上运行良好（strong memory model，后面会详解），比如x86/64，或者单核CPU。这种情况下，其实是运气成分。不用说，我们最好能认识到可能对共享变量的memory reordering，并且强制保证正确的顺序。</p>
<h4 id="Explicit-Compiler-Barriers"><a href="#Explicit-Compiler-Barriers" class="headerlink" title="Explicit Compiler Barriers"></a>Explicit Compiler Barriers</h4><p>阻止编译器重排序的最小手段就是使用特别的指令，称之为compiler barrier（编译器栅栏），前面已经提到过。下面就是一个GCC中的full compiler barrier，在Visual C++中，_ReadWriteBarrier具有相同的效果。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">int A, B;</div><div class="line"></div><div class="line">void foo() &#123;</div><div class="line">    A = B + 1;</div><div class="line">    asm volatile(&quot;&quot; ::: &quot;memory&quot;);</div><div class="line">    B = 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>加上了这个barrier，然后再打开编译器优化，内存store指令的顺序将不会被编译器重排。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ gcc -O2 -S -masm=intel foo.c</div><div class="line">$ cat foo.s</div><div class="line">        ...</div><div class="line">        mov     eax, DWORD PTR _B</div><div class="line">        add     eax, 1</div><div class="line">        mov     DWORD PTR _A, eax</div><div class="line">        mov     DWORD PTR _B, 0</div><div class="line">        ...</div></pre></td></tr></table></figure></p>
<p>类似的，如果你想保证前面的sendMessage正确工作，并且我们只关注单核系统，我们就可以使用compiler barrier。不仅发送操作需要compiler barrier来防止store操作的reordering，接收端同样需要。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">#define COMPILER_BARRIER() asm volatile(&quot;&quot; ::: &quot;memory&quot;)</div><div class="line"></div><div class="line">int Value;</div><div class="line">int IsPublished = 0;</div><div class="line"></div><div class="line">void sendValue(int x) &#123;</div><div class="line">    Value = x;</div><div class="line">    COMPILER_BARRIER();   // prevent reordering of stores</div><div class="line">    IsPublished = 1;</div><div class="line">&#125;</div><div class="line"></div><div class="line">int tryRecvValue() &#123;</div><div class="line">    if (IsPublished) &#123;</div><div class="line">        COMPILER_BARRIER(); // prevent reordering of loads</div><div class="line">        return Value;</div><div class="line">    &#125;</div><div class="line">    return -1;  // or some other value to mean not yet received</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>就像我提到的，compiler barrier对于防止单核系统的memory reordering是足够的。但是在当前的时代，多核系统是很普遍的。如果要确保我们的代码在多核环境下按照期望的顺序执行，那么仅仅只有compiler barrier是不够的，我们或者需要一个CPU fence，或者任何具有运行时memory barrier的操作。这就是下一篇文章了。</p>
<p>Linux内核以宏的方式暴露了集中CPU fence指令，比如smb_rmb，并且这些宏在单核系统下编译时会退化为compiler barrier。</p>
<h4 id="Implied-Compiler-Barriers"><a href="#Implied-Compiler-Barriers" class="headerlink" title="Implied Compiler Barriers"></a>Implied Compiler Barriers</h4><p>还有其他的方式可以阻止编译器重排序，确实，刚才提到的CPU fence就可以作为compiler barrier。这里是PowerPC上的fence命令，在GCC中是一个宏：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">#define RELEASE_FENCE() asm volatile(&quot;lwsync&quot; ::: &quot;memory&quot;)</div></pre></td></tr></table></figure></p>
<p>无论我们在代码的任何地方加上RELEASE_FENCE宏，除了阻止compiler reordering，还有processor reordering。比如它可以使我们的sendValue函数安全的运行在多核环境下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">void sendValue(int x) &#123;</div><div class="line">    Value = x;</div><div class="line">    RELEASE_FENCE();</div><div class="line">    IsPublished = 1;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在新的C++11 atomic标准库，每一个non-relaxed atomic操作都可以作为compiler barrier。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">int Value;</div><div class="line">std::atomic&lt;int&gt; IsPublished(0);</div><div class="line"></div><div class="line">void sendValue(int x) &#123;</div><div class="line">    Value = x;</div><div class="line">    // &lt;-- reordering is prevented here!</div><div class="line">    IsPublished.store(1, std::memory_order_release);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>如何所期望的那样，每一个包含compiler barrier的函数同样也是一个compiler barrier，即使是inline函数（然而微软的文档建议在早期的Visual C++编译器中可能并非如此！！！）。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">void doSomeStuff(Foo* foo) &#123;</div><div class="line">    foo-&gt;bar = 5;</div><div class="line">    sendValue(123);   // prevents reordering of neighboring assignments</div><div class="line">    foo-&gt;bar2 = foo-&gt;bar;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>实际上不管函数本身有没有compiler barrier，大多数的函数调用都可以作为memory barrier，除了inline函数，使用了pure属性的函数声明，以及使用了link-time代码生成的情况。其它情况下，调用外部函数甚至是比compiler barrier更强的barrier，因为编译器不知道函数是否有其它影响（side effects）。对于被函数潜在可见的内存，它必须忘记任何有关的假设。</p>
<p>仔细想想，这很有道理。在上面的代码片段中，假设我们的sendValue实现是在一个外部库中。Compiler怎么会知道sendValue并不依赖foo-&gt;bar呢？它不会知道。因此，为了遵守memory reordering规则，它必须不能重排sendValue函数调用周围的所有内存操作。类似的，在调用完成后，它必须从内存重新load foo-&gt;bar，而不能假设它还是5，即使优化是打开的。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ gcc -O2 -S -masm=intel dosomestuff.c</div><div class="line">$ cat dosomestuff.s</div><div class="line">        ...</div><div class="line">        mov    ebx, DWORD PTR [esp+32]</div><div class="line">        mov    DWORD PTR [ebx], 5            // Store 5 to foo-&gt;bar</div><div class="line">        mov    DWORD PTR [esp], 123</div><div class="line">        call    sendValue                     // Call sendValue</div><div class="line">        mov    eax, DWORD PTR [ebx]          // Load fresh value from foo-&gt;bar</div><div class="line">        mov    DWORD PTR [ebx+4], eax</div><div class="line">        ...</div></pre></td></tr></table></figure></p>
<p>正如你所看到的，有很多情况下编译器指令reordering都是被禁止的，甚至编译器必须重新从内存中reload一些值。我相信，人们一直以来之所以说在C中正确编写多线程程序时volatile并不是必要的，和这些隐藏的规则有很大的关系。<br>——&gt;Spark注：这里可能不完全正确，结合Meyers在关于DCLP的文章，有些编译器可以利用过程间分析来发现你对temp懂得小脑筋，再一次优化掉temp。还有一些编译环境会采用链接时内联的代码优化。<br>也就是说编译器对于本地函数可能有优化的手段，导致实际生产的memory ordering与你的期望不符。<br>&lt;——over</p>
<h3 id="Out-Of-Thin-Air-Stores"><a href="#Out-Of-Thin-Air-Stores" class="headerlink" title="Out-Of-Thin-Air Stores"></a>Out-Of-Thin-Air Stores</h3><p>（spark：out-of-thin-air，无中生有的，可见这种编译器技巧有多么的坑人！）<br>指令重排会导致lock-free编程变得很tricky？在C++11标准化之前，技术上没有能阻止编译器通向更加糟糕的窍门的技巧。特别的，编译器可以自由的引入对共享内存的store操作，如果目前还没有。这是一个极度简化的例子，灵感来自于Hans Boehm在多篇文章中提供的例子。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">int A, B;</div><div class="line"></div><div class="line">void foo() &#123;</div><div class="line">    if (A) B++;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>尽管实际中很不常见，并没有什么能阻止编译器在检查A之前将B提升到一个register，从而生成和下面等价的机器码：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">void foo() &#123;</div><div class="line">    register int r = B;  // Promote B to a register before checking A.</div><div class="line">    if (A)  r++;</div><div class="line">    B = r;    // Surprise! A new memory store where there previously was none.</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>再一次，依然遵循了memory reordering的规则。一个单线程运行的程序依然不会察觉。但是在多线程环境下，这个函数可能会将其它线程对B的任何并发修改清除掉——即使当A为0的时候，而原始代码不会这样。这类很晦涩的技术上并非不可能的情况，正是人们说C++不支持线程的一部分原因，即使我们已经愉快的使用C/C++写了几十年的多线程和lock-free的代码。</p>
<p>我不知道是否有人在实际中踩过这种“out-of-thin-air” stores的大坑（I don’t know anyone who ever fell victim to such “out-of-thin-air” stores in practice）。可能正好因为我们趋向于写的lock-free代码，并没有大量的优化对应这种模式。如果你遇到过，希望能在评论中让我知道。</p>
<p>无论如何，新的C++11标准明确禁止了编译器的这种行为，以防止它可能引入的竞争。在最新的C++11草稿的1.10.22节：<br>Compiler transformations that introduce assignments to a potentially shared memory location that would not be modified by the abstract machine are generally precluded by this standard.<br>这句话的大意是说，对不会被抽象机器修改的潜在共享内存地址，编译器不能引入赋值操作。这样，上面的那种“无中生有”类型的store优化就被禁止了，因为它引入了对r的赋值，而实际上r是不会被抽象机器修改的内存（编译器自己引入的）。</p>
<h4 id="Why-Compiler-Reordering？"><a href="#Why-Compiler-Reordering？" class="headerlink" title="Why Compiler Reordering？"></a>Why Compiler Reordering？</h4><p>就像我在开始时指出的，编译器修改内存指令的顺序的原因和processor是一样的——性能优化。这些优化是现代CPU复杂性的直接后果。<br>后面回顾了CPU的发展历程，以及编译优化的情况。不翻译了。</p>
<p>后注：还真有人在评论中提到了“out-of-thin-air”的例子：<br><a href="http://www.airs.com/blog/archives/79，Linux" target="_blank" rel="external">http://www.airs.com/blog/archives/79，Linux</a> kernel和gcc的开发者都抱怨过这种问题。</p>

      
    </div>
    <div class="article-info article-info-index">
      
      <a href="/2016/09/23/jvm/OrderAccess/" class="archive-article-date">
  	<time datetime="2016-09-23T03:30:40.000Z" itemprop="datePublished"><i class="icon-clock"></i>2016-09-23</time>
</a>
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags"></i>
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/JVM/">JVM</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<i class="icon-price-tags"></i>
	<a class="article-category-link" href="/categories/JAVA/">JAVA</a>
	</div>


      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
    <a href="/2016/09/23/jvm/java-xx-command-NativeMemoryTracking/" id="article-nav-newer" class="article-nav-link-wrap">
      <i class="icon-circle-left"></i>
      <div class="article-nav-title">
        
          Java 命令行---（NativeMemoryTracking）
        
      </div>
    </a>
  
  
    <a href="/2016/09/23/jvm/klass-desc-4/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">JVM之Klass结构介绍(三)-----Klass初始化</div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>




<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">Share to: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
	    <a class="jiathis_button_twitter"></a>
	    <a class="jiathis_button_plus"></a> 
	    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="jvm/OrderAccess" data-title="JVM之OrderAcess" data-url="http://yoursite.com/2016/09/23/jvm/OrderAccess/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>





      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2017 Corner XX
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		root: "/"
	}
</script>

<script src="/./main.js"></script>





<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


    
<div class="tools-col">
  <ul class="btn-wrap">
    
      <li class="chose" data-hook="tools-section-all"><span class="text">全部</span><i class="icon-book"></i></li>
    
    
      <li data-hook="tools-section-tag"><span class="text">标签</span><i class="icon-price-tags"></i></li>
    
    
    
      <li data-hook="tools-section-me"><span class="text">我</span><i class="icon-smile"></i></li>
    
  </ul>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all chose">
    	</section>
    

    
    	<section class="tools-section tools-section-tag">
    			<div class="widget tagcloud" id="js-tagcloud">
    				<a href="/tags/Hadoop/" style="font-size: 10px;">Hadoop</a> <a href="/tags/Hadoop-Eagle-Storm/" style="font-size: 10px;">Hadoop Eagle Storm</a> <a href="/tags/Hadoop-Hdfs/" style="font-size: 10px;">Hadoop Hdfs</a> <a href="/tags/Hadoop-Yran/" style="font-size: 10px;">Hadoop Yran</a> <a href="/tags/Hbase/" style="font-size: 16.67px;">Hbase</a> <a href="/tags/Hdfs/" style="font-size: 13.33px;">Hdfs</a> <a href="/tags/JVM/" style="font-size: 20px;">JVM</a> <a href="/tags/Kernel/" style="font-size: 13.33px;">Kernel</a> <a href="/tags/OpenJDK/" style="font-size: 13.33px;">OpenJDK</a> <a href="/tags/Phoenix/" style="font-size: 10px;">Phoenix</a> <a href="/tags/algorithm/" style="font-size: 16.67px;">algorithm</a> <a href="/tags/streamset/" style="font-size: 10px;">streamset</a>
    			</div>
    	</section>
    

    

    
    	<section class="tools-section tools-section-me">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">记录点点滴滴</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>